{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test adapted CosmiQNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append(\"../common/\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from data_utils import TRAIN_IMAGE_IDS, LABELS, TRAIN_DATA, TRAIN_WKT\n",
    "from image_utils import get_image_data, get_image_tile_data, normalize\n",
    "from visu_utils import display_img_1b, display_labels, plt_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First & last train ids :  6010_1_2 6170_4_1 25\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "all_train_ids = glob(os.path.join(TRAIN_DATA, \"*.tif\"))\n",
    "all_train_ids = np.array([s[len(TRAIN_DATA)+1:-4] for s in all_train_ids if 'mean' not in s and 'std' not in s])\n",
    "print \"First & last train ids : \", all_train_ids[0], all_train_ids[-1], len(all_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'Buildings',\n",
       " 'Misc. Manmade structures',\n",
       " 'Road',\n",
       " 'Track',\n",
       " 'Trees',\n",
       " 'Crops',\n",
       " 'Waterway',\n",
       " 'Standing water',\n",
       " 'Vehicle Large',\n",
       " 'Vehicle Small']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from data_utils import get_image_ids\n",
    "gb = TRAIN_WKT[~TRAIN_WKT['MultipolygonWKT'].str.contains(\"EMPTY\")].groupby('ClassType')\n",
    "vehicles_road_train = get_image_ids([10, 9, 3], gb)\n",
    "print len(vehicles_road_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data :  3b and MS pensharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(vehicles_road_train)\n",
    "ll = int(len(vehicles_road_train)*0.8)\n",
    "train_ids = vehicles_road_train[:ll]\n",
    "val_ids = vehicles_road_train[ll:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tile_size = (128, 128)\n",
    "# labels = np.array([9, 10, 3, 4])\n",
    "labels = np.array([9, 10, 3, 4])\n",
    "channels = np.array(list(range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS PAN\n",
      "(3440, 3440, 8) (3440, 3440, 8)\n",
      "323.844 805.357 26.6812 100.546\n"
     ]
    }
   ],
   "source": [
    "from image_utils import imwrite, compute_mean_std_on_images\n",
    "from geo_utils.GeoImage import GeoImage\n",
    "\n",
    "def compute_mean_std(image_type, feature_wise, out_shape):\n",
    "    s = ''\n",
    "    if feature_wise:\n",
    "        s = \"_feature_wise\"\n",
    "    \n",
    "    mean_fname = os.path.join(TRAIN_DATA, 'mean_%s_image%s.tif' % (image_type, s))\n",
    "    std_fname = os.path.join(TRAIN_DATA, 'std_%s_image%s.tif' %  (image_type, s))\n",
    "    if not os.path.exists(mean_fname) or not os.path.exists(std_fname):\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        mean_image, std_image = compute_mean_std_on_images(train_ids, image_type, feature_wise=feature_wise, out_shape=out_shape)\n",
    "        logging.getLogger().setLevel(logging.ERROR)\n",
    "        imwrite(mean_fname, mean_image)\n",
    "        imwrite(std_fname, std_image)\n",
    "    else:\n",
    "        mean_image = GeoImage(mean_fname).get_data()\n",
    "        std_image = GeoImage(std_fname).get_data()\n",
    "    return mean_image, std_image\n",
    "\n",
    "img_shape = (860*4, 860*4, 8)\n",
    "feature_wise = True\n",
    "mean_image, std_image = compute_mean_std('ms_pan', feature_wise, img_shape)\n",
    "        \n",
    "# print \"RGB\"    \n",
    "# print mean_rgb_image.shape, std_rgb_image.shape\n",
    "# print mean_rgb_image.min(), mean_rgb_image.max(), std_rgb_image.min(), std_rgb_image.max()\n",
    "\n",
    "print \"MS PAN\" \n",
    "print mean_image.shape, std_image.shape\n",
    "print mean_image.min(), mean_image.max(), std_image.min(), std_image.max()\n",
    "\n",
    "# print len(train_ids), len(val_ids)\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import get_image_ids\n",
    "from training_utils import tile_iterator\n",
    "\n",
    "\n",
    "def generate_images(image_ids_to_use, batch_size, resolution_level=1):\n",
    "    while True:\n",
    "        \n",
    "        X = np.zeros((batch_size, len(channels))+tile_size, dtype=np.float32)\n",
    "        Y = np.zeros((batch_size, len(labels))+tile_size, dtype=np.float32)\n",
    "        tiles = tile_iterator(image_ids_to_use,\n",
    "                              channels,\n",
    "                              labels, \n",
    "                              presence_percentage=5.0,\n",
    "                              image_type='ms_pan',\n",
    "                              label_type='label',\n",
    "                              tile_size=tile_size, \n",
    "                              mean_image=mean_image,\n",
    "                              std_image=std_image,\n",
    "                              resolution_levels=(resolution_level,),\n",
    "                              verbose_image_ids=False\n",
    "                             )\n",
    "        counter = 0\n",
    "        for x, y in tiles:     \n",
    "            \n",
    "            x = x.transpose([2,0,1])\n",
    "            y = y.transpose([2,0,1])\n",
    "\n",
    "            X[counter,:,:,:] = x\n",
    "            Y[counter,:,:,:] = y \n",
    "            counter += 1\n",
    "            if counter == batch_size:\n",
    "                yield (X, Y)\n",
    "                counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training class groups : number of pixels x appearence frequency ~ probability that a pixel of the image is of a class\n",
    "\n",
    "1. `Buildings` and `Misc. Manmade structures` and `Track` : [1, 2, 4]\n",
    "2. `Standing water` and `Road` and `Waterway` : [8, 3, 7]\n",
    "3. `Trees` and `Crops`: [5, 6]\n",
    "4. `Vehicle Small` : [10]\n",
    "5. `Vehicle Large` : [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_data_gen = generate_images(train_ids, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_n_pixels: [    0   983 30244 30421]\n",
      "Image id :  6100_2_3 373 31\n",
      "total_n_pixels: [    0   983 32013 30421]\n",
      "Image id :  6110_1_2 0 1889\n",
      "total_n_pixels: [    0  1017 32013 34397]\n",
      "Image id :  6120_2_2 463 1053\n",
      "total_n_pixels: [    0  1017 35693 34421]\n",
      "Image id :  6120_2_0 0 526\n",
      "total_n_pixels: [    0  1345 38261 37038]\n",
      "Image id :  6100_2_3 497 31\n",
      "(5, 8, 128, 128) (5, 4, 128, 128)\n",
      "-5.31553 10.9569 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_data_gen:\n",
    "    print X.shape, Y.shape\n",
    "    print X.min(), X.max(), Y.min(), Y.max()\n",
    "    \n",
    "    _n_labels = len(labels)\n",
    "    _n_channels = min(15, len(channels))\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        n, m = 3, int(_n_channels * 1.0 / 3.0 + 1.0)\n",
    "        for j in range(_n_channels):\n",
    "            if j % m == 0:\n",
    "                plt.figure(figsize=(14, 4))                \n",
    "            plt.subplot(1,m,j % m +1)\n",
    "            display_img_1b(X[i,j,:,:])\n",
    "            plt.title(\"Channels %i\" % j)\n",
    "                \n",
    "        plt.figure(figsize=(14, 6))    \n",
    "        if _n_labels < 8:\n",
    "            n, m = 1, _n_labels\n",
    "        else:\n",
    "            n, m = 3, int(_n_labels * 1.0 / 3.0 + 1.0), \n",
    "        for j in range(_n_labels):\n",
    "            plt.subplot(n, m,j+1)\n",
    "            display_img_1b(Y[i,j,:,:])\n",
    "            plt.title(\"Label : %s\" % LABELS[labels[j]])\n",
    "\n",
    "    break\n",
    "    \n",
    "    # 6120_2_2 3244 1115\n",
    "    # 6120_2_2 3275 1115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Nadam, SGD, Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from metrics import jaccard_coef, jaccard_coef_int\n",
    "\n",
    "#from cosmiqnet import cosmiqnet_zero\n",
    "from another_unet import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# model = unet(tile_size + (img_shape[2],), len(labels), n_layers=2, n_filters=64, size=3, beta=0.7)\n",
    "model = unet(len(labels), len(channels), tile_size[1], tile_size[0])\n",
    "weights_filename = os.path.join(\"weights\", \"vehicles_%i_ms.h5\" % (labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 8, 128, 128)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_58 (Convolution2D) (None, 64, 64, 64)    4672        input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_39 (LeakyReLU)         (None, 64, 64, 64)    0           convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_59 (Convolution2D) (None, 128, 32, 32)   73856       leakyrelu_39[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 128, 32, 32)   512         convolution2d_59[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_40 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_60 (Convolution2D) (None, 256, 16, 16)   295168      leakyrelu_40[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 256, 16, 16)   1024        convolution2d_60[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_41 (LeakyReLU)         (None, 256, 16, 16)   0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_61 (Convolution2D) (None, 512, 8, 8)     1180160     leakyrelu_41[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 512, 8, 8)     2048        convolution2d_61[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_42 (LeakyReLU)         (None, 512, 8, 8)     0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_62 (Convolution2D) (None, 512, 4, 4)     2359808     leakyrelu_42[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 512, 4, 4)     2048        convolution2d_62[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_43 (LeakyReLU)         (None, 512, 4, 4)     0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_63 (Convolution2D) (None, 512, 2, 2)     2359808     leakyrelu_43[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 512, 2, 2)     2048        convolution2d_63[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_44 (LeakyReLU)         (None, 512, 2, 2)     0           batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_64 (Convolution2D) (None, 512, 1, 1)     2359808     leakyrelu_44[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 512, 1, 1)     2048        convolution2d_64[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512, 1, 1)     0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_1 (UpSampling2D)    (None, 512, 2, 2)     0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_65 (Convolution2D) (None, 512, 2, 2)     2359808     upsampling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 512, 2, 2)     2048        convolution2d_65[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512, 2, 2)     0           batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_27 (Merge)                 (None, 1024, 2, 2)    0           dropout_1[0][0]                  \n",
      "                                                                   batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 1024, 2, 2)    0           merge_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_2 (UpSampling2D)    (None, 1024, 4, 4)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_66 (Convolution2D) (None, 512, 4, 4)     4719104     upsampling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 512, 4, 4)     2048        convolution2d_66[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512, 4, 4)     0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_28 (Merge)                 (None, 1024, 4, 4)    0           dropout_2[0][0]                  \n",
      "                                                                   batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1024, 4, 4)    0           merge_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_3 (UpSampling2D)    (None, 1024, 8, 8)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_67 (Convolution2D) (None, 256, 8, 8)     2359552     upsampling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 256, 8, 8)     1024        convolution2d_67[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 256, 8, 8)     0           batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_29 (Merge)                 (None, 768, 8, 8)     0           dropout_3[0][0]                  \n",
      "                                                                   batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 768, 8, 8)     0           merge_29[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_4 (UpSampling2D)    (None, 768, 16, 16)   0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_68 (Convolution2D) (None, 128, 16, 16)   884864      upsampling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 128, 16, 16)   512         convolution2d_68[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_30 (Merge)                 (None, 384, 16, 16)   0           batchnormalization_10[0][0]      \n",
      "                                                                   batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 384, 16, 16)   0           merge_30[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_5 (UpSampling2D)    (None, 384, 32, 32)   0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_69 (Convolution2D) (None, 64, 32, 32)    221248      upsampling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 64, 32, 32)    256         convolution2d_69[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_31 (Merge)                 (None, 192, 32, 32)   0           batchnormalization_11[0][0]      \n",
      "                                                                   batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 192, 32, 32)   0           merge_31[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_6 (UpSampling2D)    (None, 192, 64, 64)   0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_70 (Convolution2D) (None, 64, 64, 64)    110656      upsampling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 64, 64, 64)    256         convolution2d_70[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_32 (Merge)                 (None, 128, 64, 64)   0           batchnormalization_12[0][0]      \n",
      "                                                                   convolution2d_58[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 128, 64, 64)   0           merge_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_7 (UpSampling2D)    (None, 128, 128, 128) 0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "last_conv (Convolution2D)        (None, 2, 128, 128)   2306        upsampling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 2, 128, 128)   0           last_conv[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 19,306,690\n",
      "Trainable params: 19,298,754\n",
      "Non-trainable params: 7,936\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('weights'):\n",
    "    os.mkdir('weights')\n",
    "    \n",
    "model_checkpoint = ModelCheckpoint(weights_filename, monitor='loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'recall', 'precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 256 64\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 2509s - loss: 0.1277 - jaccard_coef: 0.2438 - jaccard_coef_int: 0.2294 - recall: 0.3544 - precision: 0.8236 - val_loss: 0.1000 - val_jaccard_coef: 0.1647 - val_jaccard_coef_int: 0.1374 - val_recall: 0.2365 - val_precision: 0.6309\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 2269s - loss: 0.0378 - jaccard_coef: 0.5184 - jaccard_coef_int: 0.5549 - recall: 0.7030 - precision: 0.8782 - val_loss: 0.1050 - val_jaccard_coef: 0.1849 - val_jaccard_coef_int: 0.1704 - val_recall: 0.2784 - val_precision: 0.5371\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 2271s - loss: 0.0295 - jaccard_coef: 0.6051 - jaccard_coef_int: 0.6499 - recall: 0.7759 - precision: 0.8903 - val_loss: 0.0991 - val_jaccard_coef: 0.2464 - val_jaccard_coef_int: 0.2416 - val_recall: 0.3773 - val_precision: 0.5473\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 2383s - loss: 0.0226 - jaccard_coef: 0.6808 - jaccard_coef_int: 0.7321 - recall: 0.8400 - precision: 0.9092 - val_loss: 0.1127 - val_jaccard_coef: 0.2159 - val_jaccard_coef_int: 0.2032 - val_recall: 0.2745 - val_precision: 0.6594\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 2032s - loss: 0.0224 - jaccard_coef: 0.6942 - jaccard_coef_int: 0.7361 - recall: 0.8395 - precision: 0.9031 - val_loss: 0.1107 - val_jaccard_coef: 0.2635 - val_jaccard_coef_int: 0.2663 - val_recall: 0.3910 - val_precision: 0.5392\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 2233s - loss: 0.0183 - jaccard_coef: 0.7317 - jaccard_coef_int: 0.7768 - recall: 0.8710 - precision: 0.9227 - val_loss: 0.1203 - val_jaccard_coef: 0.2462 - val_jaccard_coef_int: 0.2470 - val_recall: 0.3508 - val_precision: 0.5293\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 2573s - loss: 0.0125 - jaccard_coef: 0.7908 - jaccard_coef_int: 0.8354 - recall: 0.9120 - precision: 0.9390 - val_loss: 0.1415 - val_jaccard_coef: 0.2126 - val_jaccard_coef_int: 0.2092 - val_recall: 0.2960 - val_precision: 0.4871\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 2117s - loss: 0.0136 - jaccard_coef: 0.7855 - jaccard_coef_int: 0.8275 - recall: 0.9031 - precision: 0.9345 - val_loss: 0.1229 - val_jaccard_coef: 0.2829 - val_jaccard_coef_int: 0.2841 - val_recall: 0.4062 - val_precision: 0.5555\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 2167s - loss: 0.0126 - jaccard_coef: 0.8011 - jaccard_coef_int: 0.8428 - recall: 0.9129 - precision: 0.9391 - val_loss: 0.1318 - val_jaccard_coef: 0.2708 - val_jaccard_coef_int: 0.2706 - val_recall: 0.3754 - val_precision: 0.5246\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 2428s - loss: 0.0145 - jaccard_coef: 0.7877 - jaccard_coef_int: 0.8251 - recall: 0.9017 - precision: 0.9305 - val_loss: 0.1370 - val_jaccard_coef: 0.2097 - val_jaccard_coef_int: 0.1988 - val_recall: 0.2598 - val_precision: 0.6180\n"
     ]
    }
   ],
   "source": [
    "# foo = lambda x: max(x // 10, min(batch_size * 10, x))\n",
    "\n",
    "batch_size = 4\n",
    "samples_per_epoch = 256\n",
    "nb_val_samples = 64\n",
    "\n",
    "\n",
    "print batch_size, samples_per_epoch, nb_val_samples\n",
    "try:\n",
    "    history = model.fit_generator(\n",
    "        generate_images(train_ids, batch_size),\n",
    "        samples_per_epoch=samples_per_epoch, \n",
    "        nb_epoch=10,\n",
    "        validation_data=generate_images(val_ids, batch_size),\n",
    "        nb_val_samples=nb_val_samples,\n",
    "        callbacks=[model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:    \n",
    "    model.save_weights(weights_filename + '.last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 256 64\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# foo = lambda x: max(x // 10, min(batch_size * 10, x))\n",
    "\n",
    "batch_size = 4\n",
    "samples_per_epoch = 256\n",
    "nb_val_samples = 64\n",
    "\n",
    "\n",
    "print batch_size, samples_per_epoch, nb_val_samples\n",
    "try:\n",
    "    history = model.fit_generator(\n",
    "        generate_images(train_ids, batch_size),\n",
    "        samples_per_epoch=samples_per_epoch, \n",
    "        nb_epoch=10,\n",
    "        validation_data=generate_images(val_ids, batch_size),\n",
    "        nb_val_samples=nb_val_samples,\n",
    "        callbacks=[model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "except KeyboardInterrupt:    \n",
    "    model.save_weights(weights_filename + '.last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
